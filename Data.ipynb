{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087fa4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFont\n",
    "from tqdm import tqdm\n",
    "from Forgery import make_forgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c415796",
   "metadata": {},
   "outputs": [],
   "source": [
    "RVLCDIP_ROOT = \"E:/Thesis/rvl-cdip/images/\" \n",
    "OUTPUT_ROOT = \"./dataset\"\n",
    "SAMPLE_SIZE = 2000 \n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f84e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400,000 images in dataset\n"
     ]
    }
   ],
   "source": [
    "all_images = list(Path(RVLCDIP_ROOT).rglob(\"*.tif\"))\n",
    "print(f\"Found {len(all_images):,} images in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1953d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_images = random.sample(all_images, min(SAMPLE_SIZE, len(all_images)))\n",
    "\n",
    "for subset in [\"train\", \"val\", \"test\"]:\n",
    "    for label in [\"authentic\", \"forged\"]:\n",
    "        os.makedirs(os.path.join(OUTPUT_ROOT, subset, label), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0834a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.7 * len(sampled_images))\n",
    "val_split = int(0.15 * len(sampled_images))\n",
    "\n",
    "splits = {\n",
    "    \"train\": sampled_images[:train_split],\n",
    "    \"val\": sampled_images[train_split:train_split + val_split],\n",
    "    \"test\": sampled_images[train_split + val_split:]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78414804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forgery(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Very simple synthetic forgery:\n",
    "    - adds text overlay\n",
    "    - random brightness/contrast tweak\n",
    "    \"\"\"\n",
    "    img = img.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    w, h = img.size\n",
    "\n",
    "    # Try loading a font (optional)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=int(h * 0.03))\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Overlay “Edited” somewhere\n",
    "    text = \"Edited\"\n",
    "    x = random.randint(0, max(0, w - 100))\n",
    "    y = random.randint(0, max(0, h - 30))\n",
    "    draw.text((x, y), text, fill=(255, 0, 0), font=font)\n",
    "\n",
    "    # Add some global brightness/contrast noise\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(random.uniform(0.8, 1.3))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f01637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|          | 0/1400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 1400/1400 [08:21<00:00,  2.79it/s]\n",
      "Processing val: 100%|██████████| 300/300 [01:38<00:00,  3.04it/s]\n",
      "Processing test: 100%|██████████| 300/300 [01:33<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset successfully created!\n",
      "Saved under: ./dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for subset, images in splits.items():\n",
    "    for path in tqdm(images, desc=f\"Processing {subset}\"):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Save original (real)\n",
    "        base_name = path.stem + \".png\"\n",
    "        real_path = os.path.join(OUTPUT_ROOT, subset, \"authentic\", base_name)\n",
    "        img.save(real_path)\n",
    "\n",
    "        # Generate and save forged version\n",
    "        forged_img = make_forgery(img)\n",
    "        forged_path = os.path.join(OUTPUT_ROOT, subset, \"forged\", path.stem + \"_forged.png\")\n",
    "        forged_img.save(forged_path)\n",
    "\n",
    "print(\"✅ Dataset successfully created!\")\n",
    "print(f\"Saved under: {OUTPUT_ROOT}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
