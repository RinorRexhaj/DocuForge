{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41141c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096e3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['authentic', 'forged']\n",
      "Train: 1400 | Val: 300 | Test: 300\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "IMG_SIZE = 224  # ResNet50 default input size\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Directories\n",
    "train_dir = \"dataset/train\"\n",
    "val_dir = \"dataset/val\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_transforms)  # same transform as val\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f64ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.0001],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'optimizer': ['adam', 'sgd', 'adamw'],\n",
    "    'weight_decay': [1e-4, 1e-3, 0],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'hidden_units': [128, 256, 512]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "# Freeze earlier layers (optional fine-tuning)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final FC layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # combines sigmoid + binary cross entropy\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd62d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 44/44 [03:35<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc=0.701, Val Acc=0.670, Train Loss=0.642\n",
      "✅ Model saved to saved_models\\model_epoch_1.pth\n",
      "🏆 Best model updated (Val Acc=0.670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 44/44 [03:12<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc=0.819, Val Acc=0.837, Train Loss=0.541\n",
      "✅ Model saved to saved_models\\model_epoch_2.pth\n",
      "🏆 Best model updated (Val Acc=0.837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 44/44 [03:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc=0.806, Val Acc=0.823, Train Loss=0.474\n",
      "✅ Model saved to saved_models\\model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 44/44 [03:06<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc=0.819, Val Acc=0.853, Train Loss=0.450\n",
      "✅ Model saved to saved_models\\model_epoch_4.pth\n",
      "🏆 Best model updated (Val Acc=0.853)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 44/44 [03:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc=0.834, Val Acc=0.857, Train Loss=0.420\n",
      "✅ Model saved to saved_models\\model_epoch_5.pth\n",
      "🏆 Best model updated (Val Acc=0.857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 44/44 [03:07<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc=0.824, Val Acc=0.857, Train Loss=0.420\n",
      "✅ Model saved to saved_models\\model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 44/44 [03:19<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc=0.826, Val Acc=0.863, Train Loss=0.402\n",
      "✅ Model saved to saved_models\\model_epoch_7.pth\n",
      "🏆 Best model updated (Val Acc=0.863)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 44/44 [03:06<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc=0.825, Val Acc=0.853, Train Loss=0.408\n",
      "✅ Model saved to saved_models\\model_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 44/44 [03:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc=0.834, Val Acc=0.867, Train Loss=0.401\n",
      "✅ Model saved to saved_models\\model_epoch_9.pth\n",
      "🏆 Best model updated (Val Acc=0.867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 44/44 [03:08<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc=0.826, Val Acc=0.863, Train Loss=0.409\n",
      "✅ Model saved to saved_models\\model_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "SAVE_DIR = \"saved_models\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        preds = (preds > 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validation phase\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            preds = (preds > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Acc={train_acc:.3f} | Val Acc={val_acc:.3f} | Train Loss={train_loss/len(train_loader):.3f} | Val Loss={val_loss/len(val_loader):.3f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save current epoch model\n",
    "    # -----------------------------\n",
    "    model_path = os.path.join(SAVE_DIR, f\"model_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save best model\n",
    "    # -----------------------------\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_path = os.path.join(SAVE_DIR, \"best_model.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"🏆 Best model updated (Val Acc={val_acc:.3f})\")\n",
    "\n",
    "print(\"✅ Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, test_loader, criterion, device, save_dir=\"evaluation_results\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data and save all results (plots + metrics).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # ✅ Use sigmoid consistently for binary output\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            labels_np = labels.cpu().numpy().flatten()\n",
    "\n",
    "            loss = criterion(torch.tensor(probs).unsqueeze(1).to(device), labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels_np)\n",
    "\n",
    "            correct += (preds == labels_np).sum().item()\n",
    "            total += labels_np.shape[0]\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = correct / total\n",
    "\n",
    "    print(f\"\\n🧪 Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Classification Report\n",
    "    # -----------------------------------\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"], output_dict=True)\n",
    "    print(\"\\n📊 Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"]))\n",
    "\n",
    "    report_path = os.path.join(save_dir, \"classification_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"]))\n",
    "    print(f\"📝 Classification report saved to {report_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Confusion Matrix\n",
    "    # -----------------------------------\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Authentic\", \"Forged\"],\n",
    "                yticklabels=[\"Authentic\", \"Forged\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_path = os.path.join(save_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"🖼️ Confusion matrix saved to {cm_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # ROC Curve and AUC\n",
    "    # -----------------------------------\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"gray\", lw=1, linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve for Forgery Detection\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    roc_path = os.path.join(save_dir, \"roc_curve.png\")\n",
    "    plt.savefig(roc_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"📉 ROC curve saved to {roc_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Save numeric results\n",
    "    # -----------------------------------\n",
    "    results = {\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"test_accuracy\": float(test_acc),\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"precision_authentic\": report[\"Authentic\"][\"precision\"],\n",
    "        \"recall_authentic\": report[\"Authentic\"][\"recall\"],\n",
    "        \"f1_authentic\": report[\"Authentic\"][\"f1-score\"],\n",
    "        \"precision_forged\": report[\"Forged\"][\"precision\"],\n",
    "        \"recall_forged\": report[\"Forged\"][\"recall\"],\n",
    "        \"f1_forged\": report[\"Forged\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "    results_path = os.path.join(save_dir, \"metrics.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"📦 Metrics saved to {results_path}\")\n",
    "\n",
    "    print(\"\\n✅ Evaluation complete. All results saved in:\", os.path.abspath(save_dir))\n",
    "\n",
    "    return test_loss, test_acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b2af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:44<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Test Loss: 0.4044 | Test Accuracy: 0.8400\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Authentic       0.77      0.96      0.86       150\n",
      "      Forged       0.95      0.72      0.82       150\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.86      0.84      0.84       300\n",
      "weighted avg       0.86      0.84      0.84       300\n",
      "\n",
      "📝 Classification report saved to evaluation_results\\classification_report.txt\n",
      "🖼️ Confusion matrix saved to evaluation_results\\confusion_matrix.png\n",
      "📉 ROC curve saved to evaluation_results\\roc_curve.png\n",
      "📦 Metrics saved to evaluation_results\\metrics.json\n",
      "\n",
      "✅ Evaluation complete. All results saved in: c:\\Users\\PC\\Desktop\\Apps\\DocuForge\\evaluation_results\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"saved_models/best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# Run detailed evaluation\n",
    "test_loss, test_acc, roc_auc = evaluate_and_save(model, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
