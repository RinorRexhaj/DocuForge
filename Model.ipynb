{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41141c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096e3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['authentic', 'forged']\n",
      "Train: 1400 | Val: 300 | Test: 300\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "IMG_SIZE = 224  # ResNet50 default input size\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Directories\n",
    "train_dir = \"dataset/train\"\n",
    "val_dir = \"dataset/val\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_transforms)  # same transform as val\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f64ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.0001],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'optimizer': ['adam', 'sgd', 'adamw'],\n",
    "    'weight_decay': [1e-4, 1e-3, 0],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'hidden_units': [128, 256, 512]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "# Freeze earlier layers (optional fine-tuning)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final FC layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # combines sigmoid + binary cross entropy\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd62d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:35<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc=0.701, Val Acc=0.670, Train Loss=0.642\n",
      "‚úÖ Model saved to saved_models\\model_epoch_1.pth\n",
      "üèÜ Best model updated (Val Acc=0.670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:12<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc=0.819, Val Acc=0.837, Train Loss=0.541\n",
      "‚úÖ Model saved to saved_models\\model_epoch_2.pth\n",
      "üèÜ Best model updated (Val Acc=0.837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc=0.806, Val Acc=0.823, Train Loss=0.474\n",
      "‚úÖ Model saved to saved_models\\model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:06<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc=0.819, Val Acc=0.853, Train Loss=0.450\n",
      "‚úÖ Model saved to saved_models\\model_epoch_4.pth\n",
      "üèÜ Best model updated (Val Acc=0.853)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc=0.834, Val Acc=0.857, Train Loss=0.420\n",
      "‚úÖ Model saved to saved_models\\model_epoch_5.pth\n",
      "üèÜ Best model updated (Val Acc=0.857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:07<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc=0.824, Val Acc=0.857, Train Loss=0.420\n",
      "‚úÖ Model saved to saved_models\\model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:19<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc=0.826, Val Acc=0.863, Train Loss=0.402\n",
      "‚úÖ Model saved to saved_models\\model_epoch_7.pth\n",
      "üèÜ Best model updated (Val Acc=0.863)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:06<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc=0.825, Val Acc=0.853, Train Loss=0.408\n",
      "‚úÖ Model saved to saved_models\\model_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc=0.834, Val Acc=0.867, Train Loss=0.401\n",
      "‚úÖ Model saved to saved_models\\model_epoch_9.pth\n",
      "üèÜ Best model updated (Val Acc=0.867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [03:08<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc=0.826, Val Acc=0.863, Train Loss=0.409\n",
      "‚úÖ Model saved to saved_models\\model_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "SAVE_DIR = \"saved_models\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        preds = (preds > 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validation phase\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            preds = (preds > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Acc={train_acc:.3f} | Val Acc={val_acc:.3f} | Train Loss={train_loss/len(train_loader):.3f} | Val Loss={val_loss/len(val_loader):.3f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save current epoch model\n",
    "    # -----------------------------\n",
    "    model_path = os.path.join(SAVE_DIR, f\"model_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save best model\n",
    "    # -----------------------------\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_path = os.path.join(SAVE_DIR, \"best_model.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"üèÜ Best model updated (Val Acc={val_acc:.3f})\")\n",
    "\n",
    "print(\"‚úÖ Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, test_loader, criterion, device, save_dir=\"evaluation_results\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data and save all results (plots + metrics).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # ‚úÖ Use sigmoid consistently for binary output\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            labels_np = labels.cpu().numpy().flatten()\n",
    "\n",
    "            loss = criterion(torch.tensor(probs).unsqueeze(1).to(device), labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels_np)\n",
    "\n",
    "            correct += (preds == labels_np).sum().item()\n",
    "            total += labels_np.shape[0]\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = correct / total\n",
    "\n",
    "    print(f\"\\nüß™ Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Classification Report\n",
    "    # -----------------------------------\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"], output_dict=True)\n",
    "    print(\"\\nüìä Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"]))\n",
    "\n",
    "    report_path = os.path.join(save_dir, \"classification_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(classification_report(all_labels, all_preds, target_names=[\"Authentic\", \"Forged\"]))\n",
    "    print(f\"üìù Classification report saved to {report_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Confusion Matrix\n",
    "    # -----------------------------------\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Authentic\", \"Forged\"],\n",
    "                yticklabels=[\"Authentic\", \"Forged\"])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_path = os.path.join(save_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"üñºÔ∏è Confusion matrix saved to {cm_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # ROC Curve and AUC\n",
    "    # -----------------------------------\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"gray\", lw=1, linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve for Forgery Detection\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    roc_path = os.path.join(save_dir, \"roc_curve.png\")\n",
    "    plt.savefig(roc_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"üìâ ROC curve saved to {roc_path}\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Save numeric results\n",
    "    # -----------------------------------\n",
    "    results = {\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"test_accuracy\": float(test_acc),\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"precision_authentic\": report[\"Authentic\"][\"precision\"],\n",
    "        \"recall_authentic\": report[\"Authentic\"][\"recall\"],\n",
    "        \"f1_authentic\": report[\"Authentic\"][\"f1-score\"],\n",
    "        \"precision_forged\": report[\"Forged\"][\"precision\"],\n",
    "        \"recall_forged\": report[\"Forged\"][\"recall\"],\n",
    "        \"f1_forged\": report[\"Forged\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "    results_path = os.path.join(save_dir, \"metrics.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"üì¶ Metrics saved to {results_path}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Evaluation complete. All results saved in:\", os.path.abspath(save_dir))\n",
    "\n",
    "    return test_loss, test_acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b2af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:44<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Loss: 0.4044 | Test Accuracy: 0.8400\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Authentic       0.77      0.96      0.86       150\n",
      "      Forged       0.95      0.72      0.82       150\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.86      0.84      0.84       300\n",
      "weighted avg       0.86      0.84      0.84       300\n",
      "\n",
      "üìù Classification report saved to evaluation_results\\classification_report.txt\n",
      "üñºÔ∏è Confusion matrix saved to evaluation_results\\confusion_matrix.png\n",
      "üìâ ROC curve saved to evaluation_results\\roc_curve.png\n",
      "üì¶ Metrics saved to evaluation_results\\metrics.json\n",
      "\n",
      "‚úÖ Evaluation complete. All results saved in: c:\\Users\\PC\\Desktop\\Apps\\DocuForge\\evaluation_results\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"saved_models/best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# Run detailed evaluation\n",
    "test_loss, test_acc, roc_auc = evaluate_and_save(model, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
